{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2afe2701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric as tg\n",
    "from torch_geometric.nn import GINEConv\n",
    "from poker_embeddings.poker_utils.model import plot_train_loss, benchmark_dataloader\n",
    "from poker_embeddings.poker_utils.constants import DECK_DICT\n",
    "from poker_embeddings.poker_utils.datasets import UCIrvineDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e98c55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbceb808",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"../data/uc_irvine/X.csv\")\n",
    "y = pd.read_csv(\"../data/uc_irvine/y.csv\")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.6, random_state=29, stratify=y['CLASS']\n",
    "    )\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "X_val = X_val.reset_index(drop=True)\n",
    "y_val = y_val.reset_index(drop=True)\n",
    "\n",
    "train_dataset = UCIrvineDataset(X_train, y_train, add_random_cards=True, use_card_ids=True,\n",
    "                           graph=True, normalize_x=True)\n",
    "val_dataset = UCIrvineDataset(X_val, y_val, add_random_cards=True, use_card_ids=True,\n",
    "                           graph=True, normalize_x=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d505e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 410004 samples\n"
     ]
    }
   ],
   "source": [
    "benchmark_dataloader(train_dataset, batch_sizes=[128,256,512], num_workers_list=[4,8,10], num_runs=1, graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86868ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = tg.loader.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=512,\n",
    "    shuffle=True,\n",
    "    num_workers=10,\n",
    "    pin_memory=True\n",
    "    )\n",
    "valloader = tg.loader.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=512,\n",
    "    shuffle=False,\n",
    "    num_workers=10,\n",
    "    pin_memory=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b3fab30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CardGNN(nn.Module):\n",
    "    def __init__(self, card_emb_dim=16, hidden_dim=16, out_dim=16, edge_attr_dim=2):\n",
    "        super().__init__()\n",
    "        self.card_embedder = nn.Embedding(53, card_emb_dim, padding_idx=52)\n",
    "\n",
    "        self.node_mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        self.card_emb_projector = nn.Linear(card_emb_dim, hidden_dim)\n",
    "        self.gine1 = GINEConv(nn=self.node_mlp, edge_dim=edge_attr_dim)\n",
    "        self.gine2 = GINEConv(nn=self.node_mlp, edge_dim=edge_attr_dim)\n",
    "        self.final = nn.Linear(hidden_dim, out_dim)\n",
    "        self.output_layer = nn.Linear(out_dim, 10)\n",
    "    def forward(self, data):\n",
    "        card_ids = data.x\n",
    "        edge_index = data.edge_index\n",
    "        edge_attr = data.edge_attr\n",
    "\n",
    "        x = self.card_embedder(card_ids)\n",
    "        x = self.card_emb_projector(x)\n",
    "\n",
    "        x = self.gine1(x, edge_index, edge_attr)\n",
    "        x = F.relu(x)\n",
    "        x = self.gine2(x, edge_index, edge_attr)\n",
    "\n",
    "        x = self.final(x)\n",
    "        graphs_pooled = tg.utils.scatter(x, data.batch, dim=0, reduce='mean')\n",
    "        return self.output_layer(graphs_pooled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066a8dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, trainloader, optimizer, scheduler=None, device=None,\n",
    "                valloader=None, epochs=50, leftoff=0, save=True):\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    class_weights = torch.load(\"../model_weights/class_weights.pt\", weights_only=True).to(device)\n",
    "    for epoch in range(epochs):\n",
    "        tot_train_loss = 0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        model.train()\n",
    "        for batch_data in trainloader:\n",
    "            batch_data = batch_data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            logits = model(batch_data)\n",
    "\n",
    "            batch_loss = F.cross_entropy(logits, batch_data.y, weight=class_weights)\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            tot_train_loss += batch_loss.item()\n",
    "            preds = logits.argmax(dim=1)\n",
    "            correct_train += (preds == batch_data.y).sum().item()\n",
    "            total_train += batch_data.y.size(0)\n",
    "\n",
    "        avg_train_loss = tot_train_loss / len(trainloader)\n",
    "        train_acc = correct_train / total_train\n",
    "        train_losses.append(avg_train_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "\n",
    "        if valloader is not None:\n",
    "            model.eval()\n",
    "            tot_val_loss = 0\n",
    "            correct_val = 0\n",
    "            total_val = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for batch_data in valloader:\n",
    "                    batch_data = batch_data.to(device)\n",
    "                    logits = model(batch_data)\n",
    "                    batch_loss = F.cross_entropy(logits, batch_data.y, weight=class_weights)\n",
    "\n",
    "                    tot_val_loss += batch_loss.item()\n",
    "                    preds = logits.argmax(dim=1)\n",
    "                    correct_val += (preds == batch_data.y).sum().item()\n",
    "                    total_val += batch_data.y.size(0)\n",
    "\n",
    "            avg_val_loss = tot_val_loss / len(valloader)\n",
    "            val_acc = correct_val / total_val\n",
    "            val_losses.append(avg_val_loss)\n",
    "            val_accuracies.append(val_acc)\n",
    "\n",
    "        if valloader is not None:\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "                  f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "        else:\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "        if save:\n",
    "            if (epoch + 1) % 5 == 0:\n",
    "                torch.save(model.state_dict(), f\"../model_weights/hand_strength_predictor{leftoff+epoch+1}.pth\")\n",
    "\n",
    "        if scheduler is not None:\n",
    "                scheduler.step()\n",
    "\n",
    "    if valloader is not None:\n",
    "        return {\"train_loss\":train_losses,\n",
    "                \"val_loss\":val_losses,\n",
    "                \"train_accuracy\":train_accuracies,\n",
    "                \"val_accuracy\":val_accuracies}\n",
    "    else:\n",
    "        return {'train_loss':train_losses, \"train_accuracy\":train_accuracies}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78d8704",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CardGNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5100a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr= 1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38fb157",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = train_model(\n",
    "        model=model,\n",
    "        trainloader=trainloader,\n",
    "        valloader=None,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        device=device,\n",
    "        epochs=1,\n",
    "        leftoff=0,\n",
    "        save=True\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
